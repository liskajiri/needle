[project]
authors = ["Jiří Liška <70215056+liskajiri@users.noreply.github.com>"]
channels = ["https://fast.prefix.dev/conda-forge"]
description = "Library for deep learning & neural networks"
name = "needle"
platforms = ["linux-64"] #, "win-64"]
version = "0.1.0"

[tasks]
clean = "rm -rf .build/ cmake-build-debug/ python/needle/backend_ndarray/ndarray_backend*.so .pytest_cache/ .coverage"
print_backend = { cmd = "echo Using backend=$NEEDLE_BACKEND" }

download_mnist = { cmd = [
    # create directory
    "mkdir", "-p", "data/mnist", "&&",
    "curl",
    "-o", "data/mnist/train-images-idx3-ubyte.gz", "https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz",
    "-o", "data/mnist/train-labels-idx1-ubyte.gz", "https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz",
    "-o", "data/mnist/t10k-images-idx3-ubyte.gz", "https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz",
    "-o", "data/mnist/t10k-labels-idx1-ubyte.gz", "https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz"
    ], outputs = [
        "data/mnist/train-images-idx3-ubyte.gz",
        "data/mnist/train-labels-idx1-ubyte.gz",
        "data/mnist/t10k-images-idx3-ubyte.gz",
        "data/mnist/t10k-labels-idx1-ubyte.gz",
    ]}

download_tree_bank = { cmd = [
    "mkdir", "-p", "data/tree_bank/", "&&",
    "curl",
    "-o", "data/tree_bank/test.txt", "https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt",
    "-o" ,"data/tree_bank/train.txt", "https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt",
    "-o", "data/tree_bank/valid.txt", "https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt",
], outputs = ["data/tree_bank/test.txt", "data/tree_bank/train.txt", "data/tree_bank/valid.txt"]}

# TODO: refactor to use env variables for paths
download_cifar = { cmd = [
    "mkdir", "-p", "data/cifar-10/", "&&",
    "curl", "-o", "data/cifar-10/cifar-10-python.tar.gz",
    "\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"",
], outputs = ["data/cifar-10/cifar-10-python.tar.gz"]}
unpack_cifar = {cmd = "tar -xvzf data/cifar-10/cifar-10-python.tar.gz -C data/cifar-10/", inputs = ["data/cifar-10/cifar-10-python.tar.gz"], outputs = ["data/cifar-10/cifar-10-batches-py/"], depends-on = ["download_cifar"]}

download_datasets ={ cmd = ["echo", "All datasets downloaded!"], depends-on = ["download_mnist", "download_tree_bank", "unpack_cifar"]}

see_updated_deps = "pixi update --no-install --json | pixi exec pixi-diff-to-markdown > diff.md"

# TODO: gpu test/bench environment
[environments]
# jupyter = ["jupyter", "test"]
lint = {features = ["lint"], no-default-feature = true}
dev = ["dev"]
test = ["test"]
benchmark = ["benchmark"]

[dependencies]
numpy = ">=2.2.1,<3"
python = ">=3.12.8,<3.13"

# [feature.jupyter.dependencies]
# jupyter = ">=1.1.1,<2"
# ipykernel = ">=6.29.5,<7"

[feature.lint.dependencies]
ruff = ">=0.9.1,<0.10"
pre-commit = ">=4.0.1,<5"
pre-commit-hooks = ">=5.0.0,<6"
clang-format = ">=19.1.7,<20"

[feature.lint.tasks]
format = "clang-format -i -style='{IndentWidth: 4}' backends/cpu/*.cc backends/*.cu"
lint = "pre-commit run --all-files --color=always --show-diff-on-failure"
style = { depends-on = ["format", "lint"] }


[feature.dev.dependencies]
cmake = ">=3.31.4,<4"
ninja = ">=1.12.1,<2"
nanobind = ">=2.4.0,<3"
clang = ">=19.1.7,<20"
llvm-openmp = ">=19.1.7,<20"
clangxx = ">=19.1.7,<20"
libcxx = ">=19.1.7,<20"
libcxx-devel = ">=19.1.7,<20"
libcxxabi = ">=19.1.7,<20"
clang-tools = ">=19.1.7,<20"

[feature.dev.tasks]
make = { cmd = "cmake -G Ninja -S . -B .build"}
build = { cmd = ["ninja", "-C", ".build"], depends-on = ["make"] }

[feature.test.dependencies]
numdifftools = ">=0.9.41,<0.10"
pytest = ">=8.3.4,<9"
pytest-sugar = ">=1.0.0,<2"
pytest-cov = ">=6.0.0,<7"
pytest-xdist = ">=3.6.1,<4"
pytest-html = ">=4.1.1,<5"
hypothesis = ">=6.124.0,<7"
pytest-randomly = ">=3.15.0,<4"
pytorch = ">=2.5.1,<3"

[feature.test.tasks]
test = {cmd = "pytest -m 'not slow and not benchmark' -k 'not dataset'", depends-on = ["build", "print_backend"]}
# test_numpy_backend = {cmd = "pytest -m 'not slow and not benchmark' -k 'not dataset'", depends-on = ["build"], env = { NEEDLE_BACKEND = "np" }}
test_datasets = {cmd = "pytest tests/test_datasets", depends-on = ["build"]} # download_datasets
# TODO: depends on download_datasets
test_all = {cmd = """pytest
--html=$TEST_REPORT_PATH.html
--junitxml=$TEST_REPORT_PATH.xml
--cov-report html:$COVERAGE_REPORT_PATH --cov=python/needle/ tests/ --cov-fail-under=$COVERAGE_FAIL_UNDER
""", depends-on = ["build", "print_backend", "download_datasets"]}

[feature.test.activation.env]
# Save results of test to html
TEST_REPORT_PATH = "reports/test_report"
# Save code coverage report
COVERAGE_REPORT_PATH = "reports/coverage"
# Fails tests if code coverage is below 80%
COVERAGE_FAIL_UNDER = "80"

[feature.benchmark.dependencies]
# TODO: remove when Codspeed is ready
pytest = ">=8.3.4,<9"
pytest-benchmark = ">=5.1.0,<6"
# scalene = ">=1.5.41,<2"
# pytest-codspeed = ">=3.1.0,<4"
pygal = ">=3.0.5,<4"
# py-spy = ">=0.4.0,<0.5"

[feature.benchmark.tasks]
# TODO: Add --codspeed when Codspeed is ready
benchmark_matmul = {cmd = "pytest benchmarks/ --benchmark-sort=mean --benchmark-autosave --benchmark-save-data --benchmark-histogram='reports/matmul_benchmark'", depends-on = ["build"]}
# benchmark_matmul_large = {cmd = "python -m pytest tests/benchmarks/ -k 'test_matmul_large' -s --benchmark-sort=mean --benchmark-autosave --benchmark-save-data --benchmark-histogram='reports/matmul_large'", depends-on = ["build"]}
# bench_matmul = "py-spy record -o profile.svg -- python reports/test_matmul_benchmarks.py"

[activation.env]
PYTHONPATH = "./python:./apps"
