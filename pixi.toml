[workspace]
authors = ["Jiří Liška <70215056+liskajiri@users.noreply.github.com>"]
description = "Library for deep learning & neural networks"
name = "needle"
platforms = ["linux-64"]
version = "0.1.0"
# introduced advanced tasks
requires-pixi = ">=0.45.0"

channels = [
  "https://prefix.dev/pixi-build-backends",
  "https://prefix.dev/conda-forge",
]
preview = ["pixi-build"]

[package]
name = "needle"
version = "0.1.0"

[package.build]
backend = { name = "pixi-build-python", version = "*" }

[package.build.config]
# Build platform-specific package
noarch = false

[package.host-dependencies]
hatchling = "*"

[package.run-dependencies]
ndarray_backend_cpu = { path = "backends/cpu" }
numpy_backend = { path = "backends/numpy" }
python = ">=3.13.5,<3.14"


[tasks]
clean = "rm -rf .build/ cmake-build-debug/ python/needle/backend_ndarray/ndarray_backend*.so .pytest_cache/ .coverage"
print_backend = { cmd = "echo Using backend=$NEEDLE_BACKEND" }
download_datasets = { cmd = [
  "echo",
  "All datasets downloaded!",
], depends-on = [
  "download_mnist",
  "download_tree_bank",
  "unpack_cifar",
] }
see_updated_deps = "pixi update --no-install --json | pixi exec pixi-diff-to-markdown > diff.md"
start_cpu = "python -c 'import ndarray_backend_cpu as ndl; a = ndl.Array(2); ndl.fill(a, 1); print(a)'"
start_ndl = "python -c 'import needle as ndl; a = ndl.NDArray([2]); b = ndl.NDArray([3]); print(a + b)'"

[tasks.download_mnist]
args = [
  { "arg" = "save_dir", "default" = "data/mnist" },
  { "arg" = "download_path", "default" = "https://storage.googleapis.com/cvdf-datasets/mnist/" },
]
cmd = """
mkdir -p {{ save_dir }} &&
curl -o {{ save_dir }}/train-images-idx3-ubyte.gz {{ download_path }}train-images-idx3-ubyte.gz &&
curl -o {{ save_dir }}/train-labels-idx1-ubyte.gz {{ download_path }}train-labels-idx1-ubyte.gz &&
curl -o {{ save_dir }}/t10k-images-idx3-ubyte.gz {{ download_path }}t10k-images-idx3-ubyte.gz &&
curl -o {{ save_dir }}/t10k-labels-idx1-ubyte.gz {{ download_path }}t10k-labels-idx1-ubyte.gz
"""
outputs = [
  "data/mnist/train-images-idx3-ubyte.gz",
  "data/mnist/train-labels-idx1-ubyte.gz",
  "data/mnist/t10k-images-idx3-ubyte.gz",
  "data/mnist/t10k-labels-idx1-ubyte.gz",
]

[tasks.download_tree_bank]
args = [
  { "arg" = "save_dir", "default" = "data/tree_bank" },
  { "arg" = "download_path", "default" = "\"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"" },
]
cmd = """
mkdir -p {{ save_dir }} &&
curl -o {{ save_dir }}/train.txt {{ download_path }}train.txt &&
curl -o {{ save_dir }}/test.txt {{ download_path }}test.txt &&
curl -o {{ save_dir }}/valid.txt {{ download_path }}valid.txt
"""
outputs = [
  "data/tree_bank/test.txt",
  "data/tree_bank/train.txt",
  "data/tree_bank/valid.txt",
]

[tasks.download_cifar]
args = [
  { "arg" = "save_dir", "default" = "data/cifar-10" },
  { "arg" = "download_path", "default" = "\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"" },
  { "arg" = "unpack_path", "default" = "data/cifar-10/cifar-10-python.tar.gz" },
]
cmd = "mkdir -p {{ save_dir }} && curl -o {{ unpack_path }} {{ download_path }}"
outputs = ["data/cifar-10/cifar-10-python.tar.gz"]

[tasks.unpack_cifar]
args = [
  { "arg" = "save_dir", "default" = "data/cifar-10" },
  { "arg" = "unpack_path", "default" = "data/cifar-10/cifar-10-python.tar.gz" },
]
cmd = "tar -xvzf {{ unpack_path }} -C {{ save_dir }}"
inputs = ["data/cifar-10/cifar-10-python.tar.gz"]
outputs = ["data/cifar-10/cifar-10-batches-py/"]
depends-on = [{ "task" = "download_cifar" }]


# TODO: gpu test/bench environment
[environments]
notebooks = ["notebooks"]
lint = { features = ["lint"] }
test = { features = ["test"], solve-group = "test" }
benchmark = { features = ["benchmark"], solve-group = "test" }
train = ["train"]

[dependencies]
python = ">=3.13.7,<3.14"
needle = { path = "." }
ndarray_backend_cpu = { path = "backends/cpu" }
numpy_backend = { path = "backends/numpy" }

[feature.notebooks.dependencies]
marimo = ">=0.12.8,<0.13"
pytorch = ">=2.6.0,<3"

[feature.lint.dependencies]
pyright = ">=1.1.404,<2"
basedpyright = ">=1.31.3,<2"
prek = ">=0.2.3,<0.3"

[feature.lint.tasks]
lint = "prek run --all-files --color=always --show-diff-on-failure"
type_check = "pyright"

[feature.test.dependencies]
pytest = ">=8.4.1,<9"
pytest-sugar = ">=1.1.1,<2"
pytest-xdist = ">=3.8.0,<4"
hypothesis = ">=6.138.7,<7"
pytest-randomly = ">=3.15.0,<4"
pytorch = ">=2.7.1,<3"
# TODO: Investigate other coverage tools: https://github.com/plasma-umass/slipcover
coverage = ">=7.10.5,<8"


[feature.test.tasks]
test = { cmd = "pytest -n 2 -m 'not slow' -k 'not dataset'" }
test_datasets = { cmd = "pytest -n 4 tests/datasets", depends-on = [
  "download_datasets",
] }
test_doctests = { cmd = "pytest -n 0 --doctest-modules python/needle" }
test_hypothesis = { cmd = "pytest -n 8 -m 'hypothesis' --hypothesis-profile=dev" }
test_all = { cmd = """coverage run -m pytest -n auto
--junitxml=$TEST_REPORT_PATH.xml -o junit_family=legacy
""", depends-on = [
  "download_datasets",
], env = { COVERAGE_PROCESS_START = "./pyproject.toml" } }
report_coverage = { cmd = "coverage combine && coverage xml", depends-on = [
  "test_all",
] }

[feature.test.activation.env]
# Save results of test to html
TEST_REPORT_PATH = "reports/test_report"

# [feature.test.pypi-dependencies]
# pytest-testmon = ">=2.1.3, <3"

[feature.benchmark.dependencies]
pytest = ">=8.4.1,<9"
pytest-codspeed = ">=4.0.0,<5"
pytest-split = ">=0.10.0,<0.11"
pytest-benchmark = ">=5.1.0,<6"
pytorch = ">=2.7.1,<3"

[feature.benchmark.tasks]
benchmarks = { cmd = "pytest benchmarks/ --codspeed" }
benchmarks_local = { cmd = "pytest benchmarks/ $BENCHMARK_OPTIONS", env = { BENCHMARK_OPTIONS = """
--benchmark-autosave --benchmark-save-data --benchmark-compare --benchmark-group-by=name --benchmark-sort=name --benchmark-columns=min,max,mean,stddev,rounds --benchmark-compare-fail=min:20% --benchmark-min-rounds=100
""" } }
benchmark_matmul = { cmd = "pytest benchmarks/test_matmul.py --codspeed" }

[feature.benchmark.pypi-dependencies]
scalene = ">=1.5.54, <2"

[feature.train.dependencies]
tqdm = ">=4.67.1,<5"

[feature.train.tasks]
train_resnet_cifar = { cmd = "python -m apps.train_resnet --log=INFO", depends-on = [
  "download_cifar",
] }
train_resnet_mnist = { cmd = "python -m apps.train_resnet --log=INFO --dataset=mnist", depends-on = [
  "download_mnist",
] }
train_tree_bank = { cmd = "python -m apps.tree_bank --log=INFO", depends-on = [
  "download_tree_bank",
] }

[activation.env]
PYTHONPATH = "./python:./apps:.:/backends"
NEEDLE_BACKEND = "nd"
